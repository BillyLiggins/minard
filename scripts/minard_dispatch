from __future__ import print_function
import time
from redis import Redis
from itertools import count
import sys
from dispatch import Dispatch, iter_pmt_hits, get_trigger_type
from collections import defaultdict

redis = Redis()

# triggers, note: the order here is important!
# the position of the trigger in the list corresponds to the bit in the
# trigger word.
# http://snopl.us/docs/rat/user_manual/html/node43.html
TRIGGER_NAMES = \
['100L',
 '100M',
 '100H',
 '20',
 '20LB',
 'ESUML',
 'ESUMH',
 'OWLN',
 'OWLEL',
 'OWLEH',
 'PULGT',
 'PRESCL',
 'PED',
 'PONG',
 'SYNC',
 'EXTA',
 'EXT2',
 'EXT3',
 'EXT4',
 'EXT5',
 'EXT6',
 'EXT7',
 'EXT8',
 'SRAW',
 'NCD',
 'SOFGT',
 'MISS']

def main(host):
    """Connects to a dispatcher at ip address `host` and processes the dispatch stream."""
    dispatcher = Dispatch(host)
    cache = defaultdict(int)
    cache_set = {}
    cache['time'] = int(time.time())

    for i in count():
        try:
            pev = dispatcher.next(block=False)
        except (NotImplementedError, ValueError):
            pass
        except Exception as e:
            print(e,file=sys.stderr)
            continue

        # unix timestamp
        now = int(time.time())

        if i % 10 == 0:
            # heartbeat information
            p = redis.pipeline()
            p.set('dispatcher',host)
            p.expire('dispatcher',60)

            # int:{interval}:id:{timestamp}:name:{name}
            key = 'stream/int:{0:d}:id:{1:d}:name:{2:s}'
            for t in [1,60,3600]:
                id = now//t
                # expire in 100,000*[time interval]
                expire = t*100000
                p.set(key.format(t,id,'heartbeat'),1)
                p.expire(key.format(t,id,'heartbeat'),expire)

            p.execute()

        if not pev:
            time.sleep(0.001)
            continue

        gtid = pev.TriggerCardData.BcGT
        nhit = pev.NPmtHit
        run = pev.RunNumber
        subrun = pev.DaqStatus # seriously :)
        trig = get_trigger_type(pev)

        # nhit distribution
        # see http://flask.pocoo.org/snippets/71/ for this design pattern
        redis.lpush('events/id:{0:d}:name:nhit'.format(now),nhit)
        redis.expire('events/id:{0:d}:name:nhit'.format(now),3600)

        event_key = '{0:d}:{1:d}'.format(run,gtid)
        if not redis.zadd('gtids',event_key,-now):
            # event is already processed
            continue

        # trim gtid list to 100 elements
        redis.zremrangebyrank('gtids',10000,-1)

        KEY_STR = 'stream/int:{interval}:id:{id}:name:{name}'
        p = redis.pipeline()
        if now > cache['time']:
            t = cache['time']
            for key, value in cache.items():
                for interval in [1,60,3600]:
                    redis_key = KEY_STR.format(interval=interval,id=t//interval,name=key)
                    p.incrby(redis_key,value)
                    p.expire(redis_key,interval*100000)
            for key, value in cache_set.items():
                for interval in [1,60,3600]:
                    redis_key = KEY_STR.format(interval=interval,id=t//interval,name=key)
                    p.set(redis_key,value)
                    p.expire(redis_key,interval*100000)
            cache.clear()
            cache_set.clear()
            cache['time'] = now
        p.execute()
                
        # for docs on redis pipeline see http://redis.io/topics/pipelining
        p = redis.pipeline(transaction=False)

        qhs_sum = 0
        for pmt in iter_pmt_hits(pev):
            id = 16*32*pmt.CrateID + 32*pmt.BoardID + pmt.ChannelID
            p.incr('events/id:{0:d}:count'.format(now//60))
            p.expire('events/id:{0:d}:count'.format(now//60),600)
            key = 'events/id:{0:d}:channel:{1:d}'
            p.incr(key.format(now//60,id))
            p.expire(key.format(now//60,id),600)

            qhs_sum += pmt.Qhs
        p.execute()

        cache['TOTAL'] += 1
        cache['TOTAL:nhit'] += nhit
        cache['TOTAL:charge'] += qhs_sum
        cache_set['run'] = run
        cache_set['subrun'] = subrun
        cache_set['gtid'] = gtid

        for i, name in enumerate(TRIGGER_NAMES):
            if trig & (1 << i):
                cache[name] += 1
                cache[name + ':nhit'] += nhit
                cache[name + ':charge'] += qhs_sum

if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='Process SNO+ events from a dispatch stream')
    parser.add_argument('--host',default='builder1.sp.snolab.ca', help='hostname of the dispatcher')
    args = parser.parse_args()

    main(args.host)
