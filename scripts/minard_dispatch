#!/usr/bin/env python
from __future__ import print_function
import time
from redis import Redis
import sys
from dispatch import Dispatch, iter_pmt_hits, get_trigger_type
from collections import defaultdict
import traceback

redis = Redis()

# triggers, note: the order here is important!
# the position of the trigger in the list corresponds to the bit in the
# trigger word.
# http://snopl.us/docs/rat/user_manual/html/node43.html
TRIGGER_NAMES = \
['100L',
 '100M',
 '100H',
 '20',
 '20LB',
 'ESUML',
 'ESUMH',
 'OWLN',
 'OWLEL',
 'OWLEH',
 'PULGT',
 'PRESCL',
 'PED',
 'PONG',
 'SYNC',
 'EXTA',
 'EXT2',
 'EXT3',
 'EXT4',
 'EXT5',
 'EXT6',
 'EXT7',
 'EXT8',
 'SRAW',
 'NCD',
 'SOFGT',
 'MISS']

#@profile
def main(host):
    """Connects to a dispatcher at ip address `host` and processes the dispatch stream."""
    dispatcher = Dispatch(host)
    cache = defaultdict(int)
    cache_set = {}
    cache['time'] = int(time.time())
    nhit_cache = []
    event_cache = defaultdict(int)

    while True:
        try:
            pev = dispatcher.next(block=False)
        except (NotImplementedError, ValueError):
            pass
        except Exception as e:
            print(traceback.format_exc(), file=sys.stderr)
            continue

        # unix timestamp
        now = int(time.time())

        STREAM_KEY_STR = 'stream/int:{interval}:id:{id}:name:{name}'
        EVENT_KEY_STR = 'events/id:{id}:channel:{name}'
        if now > cache['time']:
            # for docs on redis pipeline see http://redis.io/topics/pipelining
            p = redis.pipeline(transaction=False)

            t = cache['time']
            for key, value in cache.items():
                for interval in [1,60,3600]:
                    redis_key = STREAM_KEY_STR.format(interval=interval,id=t//interval,name=key)
                    p.incrby(redis_key,value)
                    p.expire(redis_key,interval*100000)

            for key, value in cache_set.items():
                for interval in [1,60,3600]:
                    redis_key = STREAM_KEY_STR.format(interval=interval,id=t//interval,name=key)
                    p.set(redis_key,value)
                    p.expire(redis_key,interval*100000)

            for key, value in event_cache.items():
                redis_key = EVENT_KEY_STR.format(id=t//60,name=key)
                p.incrby(redis_key,value)
                p.expire(redis_key,600)

            p.incrby('events/id:{id}:count'.format(id=t//60),cache['TOTAL'])
            p.expire('events/id:{id}:count'.format(id=t//60),600)

            p.lpush('events/id:{id}:name:nhit'.format(id=t),*nhit_cache)
            p.expire('events/id:{id}:name:nhit'.format(id=t),3600)

            # heartbeat information
            p.set('dispatcher',host)
            p.expire('dispatcher',60)

            # int:{interval}:id:{timestamp}:name:{name}
            key = 'stream/int:{0:d}:id:{1:d}:name:{2:s}'
            for t in [1,60,3600]:
                id = now//t
                # expire in 100,000*[time interval]
                expire = t*100000
                p.set(key.format(t,id,'heartbeat'),1)
                p.expire(key.format(t,id,'heartbeat'),expire)

            cache.clear()
            cache_set.clear()
            nhit_cache = []
            event_cache.clear()
            cache['time'] = now

            p.execute()
                
        if not pev:
            time.sleep(0.001)
            continue

        run = pev.RunNumber
        gtid = pev.TriggerCardData.BcGT

        event_key = '{0:d}:{1:d}'.format(run,gtid)
        if not redis.zadd('gtids',event_key,-now):
            # event is already processed
            continue

        # trim gtid list to 10,000 elements
        redis.zremrangebyrank('gtids',10000,-1)

        nhit = pev.NPmtHit
        subrun = pev.DaqStatus # seriously :)
        trig = get_trigger_type(pev)

        # nhit distribution
        # see http://flask.pocoo.org/snippets/71/ for this design pattern
        nhit_cache += [nhit]

        qhs_sum = 0
        for pmt in iter_pmt_hits(pev):
            id = 16*32*pmt.CrateID + 32*pmt.BoardID + pmt.ChannelID
            event_cache[id] += 1

            qhs_sum += pmt.Qhs

        cache['TOTAL'] += 1
        cache['TOTAL:nhit'] += nhit
        cache['TOTAL:charge'] += qhs_sum
        cache_set['run'] = run
        cache_set['subrun'] = subrun
        cache_set['gtid'] = gtid

        for i, name in enumerate(TRIGGER_NAMES):
            if trig & (1 << i):
                cache[name] += 1
                cache[name + ':nhit'] += nhit
                cache[name + ':charge'] += qhs_sum

if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='Process SNO+ events from a dispatch stream')
    parser.add_argument('--host',default='builder1.sp.snolab.ca', help='hostname of the dispatcher')
    args = parser.parse_args()

    main(args.host)
